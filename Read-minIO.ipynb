{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3cea9c9-bee5-4806-80a2-653a6c309a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"MinIO\")\n",
    "    .master(\"local[*]\")\n",
    "\n",
    "    # путь к JAR'ам\n",
    "    .config(\n",
    "        \"spark.jars\",\n",
    "        \"/home/permyakoff/pyspark_env/spark-jars/hadoop-aws-3.3.4.jar,\"\n",
    "        \"/home/permyakoff/pyspark_env/spark-jars/aws-java-sdk-bundle-1.12.262.jar\"\n",
    "    )\n",
    "\n",
    "    # MinIO (S3A)\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://host:9100\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"login\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"password\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    .config(\n",
    "        \"spark.hadoop.fs.s3a.aws.credentials.provider\",\n",
    "        \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\"\n",
    "    )\n",
    "\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29665f5c-af9a-4782-9cbc-42207079103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.4\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    spark._jvm.org.apache.hadoop.util.VersionInfo.getVersion()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c239283-57d0-4732-9c19-8a05f40f4981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/19 11:42:28 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|{\"requestPhrase\":...|\n",
      "|{\"requestPhrase\":...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read \\\n",
    "    .text(\"s3a://wordstat/\") \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05934f9d-71ec-4951-b73a-444ae6075825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+\n",
      "|dynamics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |requestPhrase|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+\n",
      "|[{2167201, 2025-01-01, 0.018262828060562616}, {2409113, 2025-02-01, 0.02111202969283592}, {2505235, 2025-03-01, 0.02090259738612807}, {2255646, 2025-04-01, 0.019796875974182088}, {2032644, 2025-05-01, 0.019040361608368556}, {2586177, 2025-06-01, 0.02496476296189113}, {2013103, 2025-07-01, 0.019013607368042106}, {2174759, 2025-08-01, 0.020894658032161985}, {3395272, 2025-09-01, 0.02973035952361877}, {2904798, 2025-10-01, 0.024608724099023132}, {2439294, 2025-11-01, 0.021029692754908083}, {2525126, 2025-12-01, 0.022126720182650526}]|мос ру       |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"s3a://wordstat/mos_ru_dynamics__2026_01_05.json\")\n",
    "df.show( truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5475f064-7636-44a9-afca-81751f0ee593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Разворачиваем список dynamics в отдельные строки\n",
    "df_exploded = df.withColumn(\"d\", explode(col(\"dynamics\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f66c7cfc-8b33-4cef-a2ef-8068f4b9987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|количество|дата      |доля                |\n",
      "+----------+----------+--------------------+\n",
      "|2167201   |2025-01-01|0.018262828060562616|\n",
      "|2409113   |2025-02-01|0.02111202969283592 |\n",
      "|2505235   |2025-03-01|0.02090259738612807 |\n",
      "|2255646   |2025-04-01|0.019796875974182088|\n",
      "|2032644   |2025-05-01|0.019040361608368556|\n",
      "|2586177   |2025-06-01|0.02496476296189113 |\n",
      "|2013103   |2025-07-01|0.019013607368042106|\n",
      "|2174759   |2025-08-01|0.020894658032161985|\n",
      "|3395272   |2025-09-01|0.02973035952361877 |\n",
      "|2904798   |2025-10-01|0.024608724099023132|\n",
      "|2439294   |2025-11-01|0.021029692754908083|\n",
      "|2525126   |2025-12-01|0.022126720182650526|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_table = df_exploded.select(\n",
    "    col(\"d.id\").alias(\"количество\"),\n",
    "    col(\"d.date\").alias(\"дата\"),\n",
    "    col(\"d.value\").alias(\"доля\")\n",
    ")\n",
    "\n",
    "df_table.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (WSL)",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
